# coding=utf-8
import sys
import random
import routines
import copy
from orderedset import OrderedSet
from ordereddict import OrderedDict


# rule types:
# 1 - Terminal Supported Rules (TSR): fork, exit(logged)
# 2 - Context-Dependent Rules (CDR): setsid, setpgid, exit(shadow)

#  rule checkers

class proc:

    def __init__(self, p, g, s):
        self.g = g
        self.s = s
        self.p = p


# every match function returns list of [the name [args] of syscall, reconstructed Left side of rule (proc-terminal)]
# for example, ['fork', [1,1,1]]


def match_fork(p=proc('1','1','1'), c=proc('1','1','1')):
    if p.g == c.g and p.s == c.s:
        return ['fork', [p.p, p.g, p.s]]
    return ['nop', []]


def match_fork_adapter(parent=['1','1','1'], child=['1','1','1']):
    print "match fork adapter: log debug: parent: " + str(parent) + "match" + str(child)
    return match_fork(proc(parent[0],parent[1],parent[2]), proc(child[0],child[1],child[2]))


#context-dependent check: session with c.s number should exist

def match_setsid(p=proc('1', '1', '1'), c=proc('1', '1', '1'), context_dep=False, data_list=[OrderedSet(), OrderedSet()],sg_mesh=OrderedDict()):
    res = ['nop', []]
    if c.s == c.g == c.p:
        if not c.s == p.s:  # third condition should be independent inside - parsing error
            if c.s in data_list[0]:
                print "Parsing error: duplicated session leader "+str(c.s)
                exit()
            data_list[0].add(c.s)
            data_list[1].add(c.s) # group with the same number exists too
            sg_mesh[c.g] = c.s
            res = ['setsid', [c.p, p.g, p.s]]

    if not context_dep == False:
        if not c.s == p.s and c.g not in data_list[0]:
            if p.p =='1':
                print "parsing warning: session not found, trying to reconstruct the exited parent"
                return ['nop', []]

            print "parsing error: session "+str(c.s)+" not found"
            quit()

    return res


# setpgid is context-dependent rule
# групп-лидеры без reparent'а добавляются на восходящем разборе, с reparent'ом - отдельно на нисходящем
def match_setpgid(p=proc('1', '1', '1'), c=proc('1', '1', '1'), context_dep=False, data_list=[OrderedSet(), OrderedSet()], sg_mesh=OrderedDict()):
    # the most simple case: setpgid(0,0) - set new group and become group leader
    if c.p == c.g and not c.s == c.p:
        if context_dep==False:
            if c.p in data_list[1]:
                print "Parsing error: duplicated group leader " + str(c.p)
                exit()
            data_list[1].add(c.g)
            sg_mesh[c.g]=c.s

        if not c.s==p.s:
            return ['nop',[]]

        return ['setpgid('+ str(c.g) + ', ' + str(c.g)+')', [c.p, p.g, c.s]]

    # the another case is more complex and context-dependent: the group should be checked: setpgid(0,pgid) && exists(pgid,pgid,sid)
    #  - add itself to some group

    if not context_dep==False:
        if not c.g in data_list[1]:
            if p.p =='1':
                print "parsing warning: group not found, trying to reconstruct the exited parent"
                return ['nop', []]

            print "parsing error: group "+str(c.g)+" not exists!"
            quit()
         # else
        if not c.g == p.g:
            print "triggered cd setpgid"
            if c.s == p.s:
                print "triggered correct"
                return ['setpgid(self,' + p.s + ')', [c.p, p.g, c.s]]
    print "exit from " + str(p.p) + ' ' + str(p.g) + ' ' + str(p.s) + '       ' + str(c.p) + ' ' + str(c.g) + ' ' + str(c.s)
    return ['nop', []]

#context-dependent patterns match
# child: left-side only
# parent_list: whole process transformation chain
# lookup_data: context: now list of OrderedSets
# взять все родительские состояния, жадным поиском с сопоставлением КЗ-правила дополнить ребёнка слева до форка от любого из них
def cd_patterns_match(parent_list=[['1','1','1']], child=['2','1','1'], lookup_data=[], sg_mesh=OrderedDict()):

    for parent in parent_list:
        print 'cd_match:' + str(parent) + ' ' + str(child)
        if routines.is_basestring(parent):
            continue
        p = proc(parent[0], parent[1], parent[2])
        c = proc(child[0], child[1], child[2])
        proc_rules_list = [match_setsid, match_setpgid]
        for i, func in enumerate(proc_rules_list):
            subres = func(p, c, True, lookup_data, sg_mesh)
            if subres[0] != 'nop':
                return subres

    return ['nop', []]

#  context-free patterns match
def cf_patterns_match(parent=['1','1','1'], child=['2','1','1'], lookup_data=[],sg_mesh=OrderedDict()):
    p = proc(parent[0], parent[1], parent[2])
    c = proc(child[0], child[1], child[2])
    proc_rules_list = [match_setsid, match_setpgid]
    for i, func in enumerate(proc_rules_list):
        if func(p, c, False, lookup_data, sg_mesh)[0] != 'nop':
            return func(p, c)

    return ['nop', []]

'''
# put context-dependent part here !
'''


# terminal->nonterminal stack
# bp, sp, lr are indexes, lr are unused now
class stack:

    def __init__(self):
        self.bp = 0
        self.sp = 0
        self.deadsp = 0
        self.lr = 0

        self.data = list()

    def __getitem__(self, item):
        return self.data[item]

    def __setitem__(self, key, value):
        self.data[key] = value


# push the val to analyser's stack
    def push(self, val):
        self.data.append(val)
        self.sp += 1

# pop the val and return, without bp unwinding
    def pop(self):
        self.sp -= 1
        return self.data.pop()

# call: save the bp into lr and
    def call(self):
        self.lr = self.bp
        self.bp = self.sp

# unwind the bp
    def unwind(self):
        self.bp = self.lr

# delete the exited processes
    def free_exited(self):
        self.deadsp = self.sp

    def init_exited(self):
        if self.deadsp < self.sp:
            self.deadsp = self.sp

    def push_exited(self, val):
        self.data.append(val)
        self.deadsp += 1


'''
    def represent(self,  children_from, parent=routines.Node("1 1 1")):
        for i in xrange(children_from, len(parent.data)):
'''



#def match_pattern(, ):


class machine:

    def __init__(self):
        self.stack = stack()
        self.state = 'init'
        self.pidset = OrderedSet()
        self.sidset = OrderedSet()
        self.pgidset = OrderedSet()
        self.linker = OrderedDict() # link the nodes: key (stack index) : [parent stack index, index of parent's state]
        self.sg_mesh =OrderedDict()

#


def is_in_ordered(item, data=OrderedSet()):
    if item in data:
        return True
    return False

#ищет процесс, возвращает индекс множества его состояний в стеке # dfs
# fields - field filter (numbers)
# ret - list of traced return indexes (initialized with -1)
def recursive_lookup(parser, begin, end, ret, data=[1], fields=[2], strict=True):
    if begin > end:
        return

#    if (begin == end):
#        return end
    #process examining:
    for node in parser.stack[begin-1]:  # go through the states of parent
        if routines.is_basestring(node):
            continue
        j=0
        for i in fields:
            if node[i] == data[j]:
                if not strict == True:
                    ret[0] = begin
            j+=1
        if not strict == True and ret[0] != -1:
            return ret[0]

        # if strict exam:
        if j == len(data):
            ret[0] = begin
            return begin

    for i in parser.stack[begin][1]:
        return recursive_lookup(parser, i, end, ret, data, fields, strict)

def gen_index(filter='s'):
    '''
    filter_to_index = {
        's': [2],
        'g': [1],
        'p': [0],
        'gp': [1, 0],
        'sg': [2, 1],
        'pgs': [0, 1, 2]
    }
    '''
    # naive implementation
    if filter == 's':
        return [2]
    if filter == 'g':
        return [1]
    if filter == 'p':
        return [0]
    if filter == 'gp':
        return [1, 0]
    if filter == 'sg':
        return [2, 1]
    if filter == 'pgs':
        return [0, 1, 2]
    # else
    return []

# dfs search of the given fields (O(log(N)):
# the index of
def lookup_proc(parser, data=[1], filter='s', res=[-1], strict=True, recursive=True):

    iterator = 1

# non-trivial lookup usually starts from process different from INIT
    if recursive:
        recursive_lookup(parser, 1, parser.stack.deadsp, res, data, gen_index(filter), strict)
        return res

    while iterator <= parser.stack.deadsp:
        pass
    return res


# lookup the right exits with the given fields (O(n))
# the index of
def lookup_exits(parser, data, filter='s', strict=True):
    res = -1
    filter_to_index = {
        's': [2],
        'g': [1],
        'sg': [2, 3],
    }
    for iterator in (parser.stack.sp,parser.stack.deadsp,1):
        j = 0
        for i in filter_to_index[filter]:
            if parser.stack.data[iterator][-1][i] == data[j]:
                if not strict == True:
                    res = iterator

                j += 1
        if j == len(data):
            return iterator

    return res

def pick_random_pid(parser):
    return random.choice([x for x in range(2^16-1) if x not in parser.pidset])


def cd_down(parser, it, sp, check_exits=True):
    while it < sp - 1: # from start to the bottom of the stack
        it += 1

        if routines.is_link(parser.stack[it]):

            for link in parser.stack[it][1]: # go through the all of 1st children

                match_res = cd_patterns_match(parser.stack[it - 1], parser.stack[link - 1][0], [parser.sidset, parser.pgidset],parser.sg_mesh)

                if not match_res[0] == 'nop':
                    # apply the matched pattern: left side of rule reconstruction
                    print "\t match OK: " + str(match_res[0]) + str(match_res[1])
                    parser.stack[link-1].insert(0, match_res[0])
                    parser.stack[link-1].insert(0, match_res[1])

#attach: checker & linker:

                for node in parser.stack[it-1]: # go through the states of parent
                    if routines.is_basestring(node):
                        continue

                    subres = match_fork_adapter(node, parser.stack[link-1][0])
                    if subres[0] == 'fork':
                        print "CURRENT PARENT IS FOUND"

                        parser.linker[parser.stack.data.index(parser.stack[link-1])] = [it-1, parser.stack[it-1].index(node)]
                        break

                    if node == parser.stack[it-1][-1] and subres[0] == 'nop':
#############################################################
#############################################################
#############################################################
#############################################################
# check non-terminal exits there #############################################################
##########################################################################################################################
#############################################################################################################################

                        if check_exits and parser.stack[link][0] == 1: # it is init's child

                            if is_in_ordered(parser.stack[link-1][0][2], parser.sidset): #SESSION EXISTS
                                # фильтр конструируется следующим образом: если не нашлось 'sg', отдаётся 's'
                                suitable_proc_index = lookup_exits(parser,parser.stack[link-1][0][2], 'sg')
                                if suitable_proc_index == -1:
                                    suitable_proc_index = lookup_exits(parser, parser.stack[link - 1][0][2], 's')
                                if suitable_proc_index == -1: # there are no exited processes in this session, but session exists
#1) find sg or s place to match the exited proc;
# lookup_proc is restricted wrapper of 'recursive_lookup' DFS-routine
# suitable_proc_index should be traced through the tree by DFS

                                    suitable_proc_index = lookup_proc(parser, [parser.stack[link-1][0][2], parser.stack[link-1][0][1]], "sg")
                                    if suitable_proc_index == -1:
                                        suitable_proc_index = lookup_proc(parser, [parser.stack[link - 1][0][2],parser.stack[link - 1][0][1]], "s")
                                        new_pid = pick_random_pid(parser)
                                        parser.stack.push_exited([[new_pid, parser.stack[suitable_proc_index][0][1],
                                             parser.stack[suitable_proc_index][0][2]]])

#2) add new exited proc and attach it to this place:

                                print "Reverse reparenting: suitable exit is found, trying ro reparent " + str(link-1)+" to "+str(suitable_proc_index)
                                # но ещё нужно проверить группу: если p!=pg и такая группа уже есть в отличной сессии - parsing warning:
                                # нужна доп. проверка непройденных детей: многие из них могут стать групп-лидерами в той же сессии
                                # станут - можно будет сделать реверсный реперент, не станут  - нельзя
                                # поэтому реализуем логику с картинки
                                # if !sg_mesh[g]
                                # !!! Логика нижележащей строки уже покрыта восходящим разбором: сессию добавляет только её лидер
                                # !!! for lookup in laydown_init_children:
                                # !!! if g==p && g.s == S(p) -> ok;
                                # аналогично если нет exit, но там аттач к подходящему в нужной сессии
                                # правильность сессии обеспечивает то что setsid можно сделать только 1 раз

                                # разворачивание в стеке не аффектит данные о сессиях и группах, поэтому можно добавить(если что - для отладки)
                                # на данном шаге нас интересует только терминальное состояние ребёнка, которому восстанавливаем родителя:
                                # остальное - проверить и решить, нужен ли setpgid
                                if not (parser.stack[link-1][-1][1] == parser.stack[suitable_proc_index][-1][1]):
                                    parser.stack[link - 1].insert(0,'setpgid(0, ' + str(parser.stack[link - 1][0][1]) +')')

                                    parser.stack[link - 1].insert(0, [parser.stack[link - 1][1][0],
                                                                  parser.stack[suitable_proc_index][-1][1],
                                                                  parser.stack[link - 1][1][2]])

                                # проверка группы:
                                if not (parser.stack[link - 1][-1][0] == parser.stack[link - 1][-1][1]): # examine the group: g != p --> check the group

                                    if int(parser.stack[link-1][-1][1]) in parser.sg_mesh.keys(): # the group exists
                                        # wrong session checking:
                                        if not parser.sg_mesh[int(parser.stack[link - 1][-1][1])] == int(parser.stack[suitable_proc_index][-1][2]) or not \
                                        (parser.stack[link-1][-1][2] == parser.stack[suitable_proc_index][-1][2]):
                                            print "Parsing error: setpgid to exising group in different session" + str(suitable_proc_index)
                                            exit()

                                        # the session is right
                                    else: #group not exists - error
                                        print "Parsing error: group not exists "+ parser.stack[link-1][-1][1]
                                        exit()

                                # maybe else is redundant - on upward %)
                                # link construction
                                # ______________________________________
                                parser.linker[link - 1] = [
                                     suitable_proc_index, -1]  # link child to the exited process
                                parser.stack[link][0] = parser.stack.deadsp
                                # ______________________________________
                                # parser.linker:
                                # присоединить к нему, с проверкой принадлежности к сессии.[через sg_mesh]
                                pass
                            else: # no session:
#                                    and not is_in_ordered(parser.stack[link-1][0][2], parser.sidset):#the worst case: reparented rudiment

                                parser.stack.init_exited() #init the deadstack
                                parser.stack.push_exited([
                                    [parser.stack[link-1][0][2], parser.stack[0][0][1], parser.stack[0][0][2]],
                                    'setsid(' + str(parser.stack[link-1][0][2])+')',
                                    [parser.stack[link-1][0][2], parser.stack[link-1][0][2], parser.stack[link-1][0][2]]
                                ]) # add the exited with all trace of syscalls: fork -> setsid -> exit


                                parser.sidset.add(parser.stack[link-1][0][2])
                                parser.pidset.add(parser.stack[link-1][0][2])
                                parser.pgidset.add(parser.stack[link-1][0][2])
                                parser.sg_mesh[parser.stack[link-1][0][2]]=parser.stack[link-1][0][2]

                                #match_setpgid(,parser.stack.link)
                                parser.stack[link-1].insert(0, 'setpgid(0, ' + str(parser.stack[link-1][0][1]) +')')
                                parser.stack[link-1].insert(0, [parser.stack[link-1][1][0], parser.stack[parser.stack.deadsp-1][-1][1] ,parser.stack[link-1][1][2]])
                                #parser.linker:

                                parser.linker[parser.stack.data.index(parser.stack[link - 1])] = [parser.stack.deadsp-1,-1] # link child to the exited process
                                parser.stack[link][0] = parser.stack.deadsp

                                parser.stack[1][1][parser.stack[it][1].index(link)] = parser.stack.deadsp
                                parser.stack.push_exited([1, [link]])
                        # attach and ok ...
                            continue
# if not found

                        print "Parsing error: string is incorrect (troubles with " + str(node) + " and " + str(parser.stack[link-1][0])
                        quit()

            if not len(parser.stack[it][1]): # the leaf-node
                continue

    # then return
    return

def tree_visualize(parser, root, ptree_storage=OrderedDict()):
    for i in parser.linker.keys():
        right = routines.Node(str(parser.stack[i][0]), parent=ptree_storage[parser.linker[i][0]][parser.linker[i][1]/2])
        ptree_storage[i] = [right]

        for j in xrange(2, len(parser.stack[i])):
            if routines.is_basestring(parser.stack[i][j]):
                continue
            right = routines.Node(str(parser.stack[i][j-1]) + "->" + str(parser.stack[i][j]), parent=right)
            ptree_storage[i].append(right)

    return root

# 'parse' input should be normalized
def normalize(s="1 1 1[]"):
    for i in xrange(1, len(str)-1):
        if (s[i] =='[' or s[i] ==']') and not s[i+1] == ' ':
            s = s[:i]+' '+s[i:]
        if (s[i] =='[' or s[i] ==']') and not s[i-1] == ' ':
            s = s[:i-1]+' '+s[i-1:]
    return str
# parser is a left context-free parser with context-dependent post-check (In compiler-like SA manner).
# 1) context-free upwarding until ']' with non-empty stack. Then trusted (context-free) downwarding on stackframe with reconstruction.
# 2) after the whole string is ended - full untrusted (context-dependent) process check.

#'optimized' should solve the problem of non-optimal setpgids (see example 1 1 1 -> 2 2 1 -> 3 1 1)

# X p g s [] supporting implementation - exits {now is redundant}

def parse(argst="100 101 102 [ ]", optimized=False):
    line = argst.split(' ')

    parser = machine()

    num = 0
    while num in xrange(len(line)):
        if (line[num]).isdigit() and (line[num+1]).isdigit() and (line[num+2]).isdigit():
            parser.state = 'proc'
            parser.stack.push([[line[num], line[num+1], line[num+2]]])

            # 'X'-suffix: the process is dead ('exit' syscall was executed)
            if line[num+3] == 'X':
                parser.stack[-1][-1].append('DEAD')
                num += 1
            num += 3

            try:
                parser.pidset.index(int(line[num-3]))
            except ValueError:
                parser.pidset.add(int(line[num-3]))

            else:
                print "Parsing error: pid duplicate"
                break

        if line[num] == '[':
            if parser.state == 'proc':
                parser.state = 'call'
                parser.stack.push([parser.stack.bp])
                parser.stack[-1].append([])

                parser.stack.bp = parser.stack.sp - 1

        elif line[num] == ']':

            if parser.stack.sp - parser.stack.bp == 1:  # leaf-node

                parser.state == 'revert'

                parser.stack.bp = parser.stack[parser.stack.bp][0]

                num += 1
                continue

            else:

                #  not leaf node - visit all of 1st level children
                it = parser.stack.bp
                while it < parser.stack.sp - 1:

                    it += 1

                    print it
                    # check all context rules, then:
                    if not (routines.is_link(parser.stack[it])):
                        inner_it = -1
                        if parser.stack[it+1][0] > parser.stack.bp:
                            it += 1
                            continue
                        #else append the children's basepointers into the list near the parent basepointer
                        # (to handle them in context-dependent downward)
                        parser.stack[parser.stack.bp][1].append(it+1)
                        # log info:
                        print "match " + str(parser.stack[parser.stack.bp-1][inner_it])+" and "+str(parser.stack[it][inner_it])
                        match_res = cf_patterns_match(parser.stack[parser.stack.bp-1][inner_it], parser.stack[it][inner_it], [parser.sidset, parser.pgidset],parser.sg_mesh)
                        # insert the reconstructed part into the stack on the current child position (left-side)

                        if not match_res[0] == 'nop':
                            # apply the matched pattern: left side of rule reconstruction
                            print "\t match OK: "+str(match_res[0]) + str(match_res[1])
                            parser.stack[it].insert(0, match_res[0])
                            parser.stack[it].insert(0, match_res[1])

                    else:
                        continue

                parser.state == 'revert'
                parser.stack.bp = parser.stack[parser.stack.bp][0]

        else:
            print "Parsing error: " + line[num]
            break

        num += 1

    # post-analyse: context-dependent part
    print "LOG debug: final stack dump before top-down walk"
    for i in xrange(0, len(parser.stack.data)):
        print str(i) + ": " + str(parser.stack.data[i])

    print "LOG debug: pgroups: " + str(parser.pgidset)
    print "LOG debug: sessions: " + str(parser.sidset)
    it = 0

    print "Context-dependent part"

    ptree_root = routines.Node(str(parser.stack[0][0]), parser.stack[0][0][0], parser.stack[0][0][1], parser.stack[0][0][2])

    parser.sidset.add(parser.stack[0][0][2])
    parser.pgidset.add(parser.stack[0][0][1])
    parser.sg_mesh[parser.stack[0][0][1]] = parser.stack[0][0][2]

    cd_down(parser, 0, parser.stack.sp)
    routines.log_output(ptree_root, "", 1, 0)
    print parser.linker
    # post-print of stack:
    for i in xrange(0, len(parser.stack.data)):
        print str(i) + ": " + str(parser.stack.data[i])

    print parser.pgidset
    print "STREE_VISUALIZE(): "
    root = routines.Node("['1','1','1']", parent=None)

    ptree_tmp = OrderedDict()
    ptree_tmp[0] = [root]
#    res = tree_visualize(parser, root, ptree_tmp)
#    print "TEST TREE:"
#    routines.log_output(root, "", 1, 0)
    dfs_result = [-1]
#   recursive_lookup(parser, 1, parser.stack.deadsp, dfs_result, ['13','1','1'], [0, 1, 2])
    #(parser, data = [1], filter = 's', res = [-1](parser, data=[1], filter='s', res=[-1]
    dfs_result = lookup_proc(parser, [5, 2] , "sg", dfs_result)
    print "dfs_test:"
    print dfs_result

parse("1 1 1 [ 11 1 1 [ 13 1 1 [ ] ] 2 2 5 [ ] ]") # 3 3 2 [ 6 2 2 [ 7 3 2 [ ] ] ] ] 5 5 5 [ 10 5 1 [ ] ] ]")  # 6 6 5 [ ] ]")  # 6 6 5 [ ] ]")

